{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords count sn remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this script  we are processing the texts fo SN remarks column and finding the new possible keywords for RCA. We are finf the frequecy of words present in SN_Reamrks and based on frequency come with the keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file with SN_Remarks data to python\n",
    "import pandas as pd\n",
    "keywords = pd.read_excel(\"C:\\\\Users\\\\ijohan\\\\Desktop\\\\TNB_PROJECT\\\\source_data\\\\may\\\\data_may_src_listing.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the columns name with underscore\n",
    "keywords.columns = keywords.columns.str.replace(' ','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the columns name with underscore\n",
    "keywords.columns = keywords.columns.str.replace('-','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = keywords[['Service_Request_ID','CA_Number','Category', 'Sub_Category','SN_Number','SN_Remarks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Service_Request_ID</th>\n",
       "      <th>CA_Number</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub_Category</th>\n",
       "      <th>SN_Number</th>\n",
       "      <th>SN_Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000640084</td>\n",
       "      <td>220867052707</td>\n",
       "      <td>OPC Meter Accuracy Test</td>\n",
       "      <td>Low Bill Normal</td>\n",
       "      <td>201000155754</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000655605</td>\n",
       "      <td>210039732001</td>\n",
       "      <td>OPC Meter Accuracy Test</td>\n",
       "      <td>High Bill Normal</td>\n",
       "      <td>201000159237</td>\n",
       "      <td>Internal note 24.05.2019 17:29:23 60068220  P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000662021</td>\n",
       "      <td>220061331308</td>\n",
       "      <td>Check Meter Reading</td>\n",
       "      <td>Bill Too High</td>\n",
       "      <td>218000610820</td>\n",
       "      <td>Internal note28.05.2019 14:28:19 10095089peng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000665216</td>\n",
       "      <td>220543677404</td>\n",
       "      <td>Check Meter Reading</td>\n",
       "      <td>Bill Too High</td>\n",
       "      <td>218000612074</td>\n",
       "      <td>Internal note29.05.2019 13:14:06 10092679PENG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000664889</td>\n",
       "      <td>220715742409</td>\n",
       "      <td>Check Meter Reading</td>\n",
       "      <td>Bill Too High</td>\n",
       "      <td>218000612432</td>\n",
       "      <td>Internal note29.05.2019 15:46:06 10092139peng...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Service_Request_ID     CA_Number                 Category  \\\n",
       "0          1000640084  220867052707  OPC Meter Accuracy Test   \n",
       "1          1000655605  210039732001  OPC Meter Accuracy Test   \n",
       "2          1000662021  220061331308      Check Meter Reading   \n",
       "3          1000665216  220543677404      Check Meter Reading   \n",
       "4          1000664889  220715742409      Check Meter Reading   \n",
       "\n",
       "       Sub_Category     SN_Number  \\\n",
       "0   Low Bill Normal  201000155754   \n",
       "1  High Bill Normal  201000159237   \n",
       "2     Bill Too High  218000610820   \n",
       "3     Bill Too High  218000612074   \n",
       "4     Bill Too High  218000612432   \n",
       "\n",
       "                                          SN_Remarks  \n",
       "0                                                NaN  \n",
       "1   Internal note 24.05.2019 17:29:23 60068220  P...  \n",
       "2   Internal note28.05.2019 14:28:19 10095089peng...  \n",
       "3   Internal note29.05.2019 13:14:06 10092679PENG...  \n",
       "4   Internal note29.05.2019 15:46:06 10092139peng...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords.loc[:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning SN remarks column, like removing speacial characters and numeric strings from the comment to get clean words and generate unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate unigrams \n",
    "i = keywords.SN_Remarks\\\n",
    "      .str.lower()\\\n",
    "      .str.replace('[^a-z\\s]', '')\\\n",
    "      .str.split(expand=True)\\\n",
    "      .stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate bigrams by concatenating unigram columns\n",
    "j = i + ' ' + i.shift(-1)\n",
    "# generate trigrams by concatenating unigram and bigram columns\n",
    "k = j + ' ' + i.shift(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all series vertically, and remove NaNs\n",
    "k_grams = pd.concat([i, j, k]).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating starting for 2gram onwards\n",
    "# concatenate all series vertically, and remove NaNs\n",
    "k_grams = pd.concat([j, k]).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column name words\n",
    "k_grams = pd.DataFrame(k_grams, columns=['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1499138</th>\n",
       "      <td>bilbil enbloc iaitu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499139</th>\n",
       "      <td>enbloc iaitu serentak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499140</th>\n",
       "      <td>iaitu serentak pada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499141</th>\n",
       "      <td>serentak pada cukup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499142</th>\n",
       "      <td>pada cukup bulan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         words\n",
       "1499138    bilbil enbloc iaitu\n",
       "1499139  enbloc iaitu serentak\n",
       "1499140    iaitu serentak pada\n",
       "1499141    serentak pada cukup\n",
       "1499142       pada cukup bulan"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_grams.head()\n",
    "k_grams.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = k_grams['words'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_grams_count = pd.DataFrame(counts.items(), columns=['words', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>internal note</td>\n",
       "      <td>15015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>note pengguna</td>\n",
       "      <td>7681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>internal note pengguna</td>\n",
       "      <td>7645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pengguna maklum</td>\n",
       "      <td>6536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>note pengguna maklum</td>\n",
       "      <td>4127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    words  count\n",
       "0           internal note  15015\n",
       "1           note pengguna   7681\n",
       "2  internal note pengguna   7645\n",
       "3         pengguna maklum   6536\n",
       "4    note pengguna maklum   4127"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_grams_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489370"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(k_grams_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_grams_count.to_csv(\"NGRAM_KEYWORD_COUNT_MAY.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating count group by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# craeting word count based on the category\n",
    "import pandas as pd\n",
    "keywords_cat = pd.read_excel(\"C:\\\\Users\\\\ijohan\\\\Desktop\\\\TNB_PROJECT\\\\source_data\\\\may\\\\DATA_MAY_UPDATED_WITH24JUNSTATUS_INFO_COMPLAINTS_RCA_SNREMARK_ANALYSIS_24JUNE2019.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_cat = keywords_cat[['SN_Number', 'Category', 'SubCategory', 'SN_Remark']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Estimated Bill', 'Wrong Reading', 'Meter Faulty', 'Bill Received',\n",
       "       'No RMR bill received', 'Meter Crossing'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_cat.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frame for each type, breaking main data frame in to smaller based on the Category.\n",
    "Meter_Crossing = keywords_cat.loc[keywords_cat['Category'] == 'Meter Crossing'] #52\n",
    "Meter_Faulty = keywords_cat.loc[keywords_cat['Category'] == 'Meter Faulty'] # 863\n",
    "Wrong_Reading = keywords_cat.loc[keywords_cat['Category'] == 'Wrong Reading'] # 1111\n",
    "Bill_Received = keywords_cat.loc[keywords_cat['Category'] == 'Bill Received'] # 97\n",
    "Estimated_Bill = keywords_cat.loc[keywords_cat['Category'] == 'Estimated Bill'] # 109\n",
    "No_RMR_bill_received = keywords_cat.loc[keywords_cat['Category'] == 'No RMR bill received'] # 9\n",
    "Product_Change = keywords_cat.loc[keywords_cat['Category'] == 'Product Change'] # 1\n",
    "\n",
    "# Meter_Crossing, Meter_Faulty, Wrong_Reading, Bill_Received, Estimated_Bill, No_RMR_bill_received "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Product_Change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Take the script of first section of this file which is used for the word freaquency count in SN_remarks column and perform the same action on all the smaller data frame based on the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate unigrams \n",
    "i = Meter_Crossing.SN_Remark\\\n",
    "      .str.lower()\\\n",
    "      .str.replace('[^a-z\\s]', '')\\\n",
    "      .str.split(expand=True)\\\n",
    "      .stack()\n",
    "\n",
    "# generate bigrams by concatenating unigram columns\n",
    "j = i + ' ' + i.shift(-1)\n",
    "# generate trigrams by concatenating unigram and bigram columns\n",
    "k = j + ' ' + i.shift(-2)\n",
    "\n",
    "# concatenate all series vertically, and remove NaNs\n",
    "Meter_Crossing = pd.concat([i, j, k]).dropna().reset_index(drop=True)\n",
    "Meter_Crossing = pd.DataFrame(Meter_Crossing, columns=['words'])\n",
    "counts = Meter_Crossing['words'].value_counts().to_dict()\n",
    "Meter_Crossing_count = pd.DataFrame(counts.items(), columns=['words', 'count'])\n",
    "Meter_Crossing_count['category'] = 'Meter Crossing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate unigrams \n",
    "i = Wrong_Reading.SN_Remark\\\n",
    "      .str.lower()\\\n",
    "      .str.replace('[^a-z\\s]', '')\\\n",
    "      .str.split(expand=True)\\\n",
    "      .stack()\n",
    "\n",
    "# generate bigrams by concatenating unigram columns\n",
    "j = i + ' ' + i.shift(-1)\n",
    "# generate trigrams by concatenating unigram and bigram columns\n",
    "k = j + ' ' + i.shift(-2)\n",
    "\n",
    "# concatenate all series vertically, and remove NaNs\n",
    "Wrong_Reading = pd.concat([i, j, k]).dropna().reset_index(drop=True)\n",
    "Wrong_Reading = pd.DataFrame(Wrong_Reading, columns=['words'])\n",
    "counts = Wrong_Reading['words'].value_counts().to_dict()\n",
    "Wrong_Reading_count = pd.DataFrame(counts.items(), columns=['words', 'count'])\n",
    "Wrong_Reading_count['category'] = 'Wrong Reading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bill_Received\n",
    "# generate unigrams \n",
    "i = Bill_Received.SN_Remark\\\n",
    "      .str.lower()\\\n",
    "      .str.replace('[^a-z\\s]', '')\\\n",
    "      .str.split(expand=True)\\\n",
    "      .stack()\n",
    "\n",
    "# generate bigrams by concatenating unigram columns\n",
    "j = i + ' ' + i.shift(-1)\n",
    "# generate trigrams by concatenating unigram and bigram columns\n",
    "k = j + ' ' + i.shift(-2)\n",
    "\n",
    "# concatenate all series vertically, and remove NaNs\n",
    "Bill_Received = pd.concat([i, j, k]).dropna().reset_index(drop=True)\n",
    "Bill_Received = pd.DataFrame(Bill_Received, columns=['words'])\n",
    "counts = Bill_Received['words'].value_counts().to_dict()\n",
    "Bill_Received_count = pd.DataFrame(counts.items(), columns=['words', 'count'])\n",
    "Bill_Received_count['category'] = 'Bill Received'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimated_Bill\n",
    "# generate unigrams \n",
    "i = Estimated_Bill.SN_Remark\\\n",
    "      .str.lower()\\\n",
    "      .str.replace('[^a-z\\s]', '')\\\n",
    "      .str.split(expand=True)\\\n",
    "      .stack()\n",
    "\n",
    "# generate bigrams by concatenating unigram columns\n",
    "j = i + ' ' + i.shift(-1)\n",
    "# generate trigrams by concatenating unigram and bigram columns\n",
    "k = j + ' ' + i.shift(-2)\n",
    "\n",
    "# concatenate all series vertically, and remove NaNs\n",
    "Estimated_Bill = pd.concat([i, j, k]).dropna().reset_index(drop=True)\n",
    "Estimated_Bill = pd.DataFrame(Estimated_Bill, columns=['words'])\n",
    "counts = Estimated_Bill['words'].value_counts().to_dict()\n",
    "Estimated_Bill_count = pd.DataFrame(counts.items(), columns=['words', 'count'])\n",
    "Estimated_Bill_count['category'] = 'Estimated Bill'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No_RMR_bill_received\n",
    "# generate unigrams \n",
    "i = No_RMR_bill_received.SN_Remark\\\n",
    "      .str.lower()\\\n",
    "      .str.replace('[^a-z\\s]', '')\\\n",
    "      .str.split(expand=True)\\\n",
    "      .stack()\n",
    "\n",
    "# generate bigrams by concatenating unigram columns\n",
    "j = i + ' ' + i.shift(-1)\n",
    "# generate trigrams by concatenating unigram and bigram columns\n",
    "k = j + ' ' + i.shift(-2)\n",
    "\n",
    "# concatenate all series vertically, and remove NaNs\n",
    "No_RMR_bill_received = pd.concat([i, j, k]).dropna().reset_index(drop=True)\n",
    "No_RMR_bill_received = pd.DataFrame(No_RMR_bill_received, columns=['words'])\n",
    "counts = No_RMR_bill_received['words'].value_counts().to_dict()\n",
    "No_RMR_bill_received_count = pd.DataFrame(counts.items(), columns=['words', 'count'])\n",
    "No_RMR_bill_received_count['category'] = 'No RMR bill received'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate unigrams \n",
    "i = Meter_Faulty.SN_Remark\\\n",
    "      .str.lower()\\\n",
    "      .str.replace('[^a-z\\s]', '')\\\n",
    "      .str.split(expand=True)\\\n",
    "      .stack()\n",
    "\n",
    "# generate bigrams by concatenating unigram columns\n",
    "j = i + ' ' + i.shift(-1)\n",
    "# generate trigrams by concatenating unigram and bigram columns\n",
    "k = j + ' ' + i.shift(-2)\n",
    "\n",
    "# concatenate all series vertically, and remove NaNs\n",
    "Meter_Faulty = pd.concat([i, j, k]).dropna().reset_index(drop=True)\n",
    "Meter_Faulty = pd.DataFrame(Meter_Faulty, columns=['words'])\n",
    "counts = Meter_Faulty['words'].value_counts().to_dict()\n",
    "Meter_Faulty_count = pd.DataFrame(counts.items(), columns=['words', 'count'])\n",
    "Meter_Faulty_count['category'] = 'Meter Faulty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat all the data frames # Bill_Received_count , No_RMR_bill_received_count, Product Change\n",
    "count_category = pd.concat([Meter_Crossing_count, Meter_Faulty_count, Wrong_Reading_count, Estimated_Bill_count,No_RMR_bill_received_count], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meter</td>\n",
       "      <td>113</td>\n",
       "      <td>Meter Crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pengguna</td>\n",
       "      <td>66</td>\n",
       "      <td>Meter Crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dan</td>\n",
       "      <td>50</td>\n",
       "      <td>Meter Crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>39</td>\n",
       "      <td>Meter Crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>di</td>\n",
       "      <td>38</td>\n",
       "      <td>Meter Crossing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      words count        category\n",
       "0     meter   113  Meter Crossing\n",
       "1  pengguna    66  Meter Crossing\n",
       "2       dan    50  Meter Crossing\n",
       "3        no    39  Meter Crossing\n",
       "4        di    38  Meter Crossing"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_category.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging based on ethinicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SN_Remarks_Working_File_18062019.xlsx\n",
    "import pandas as pd\n",
    "ethni = pd.read_excel(\"C:\\\\Users\\\\ijohan\\\\Desktop\\\\TNB_PROJECT\\\\source_data\\\\may\\\\SR&COMPLAINTS_ANALYSIS.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_ch = pd.read_csv(\"C:\\\\Users\\\\ijohan\\\\Desktop\\\\TNB_PROJECT\\\\source_data\\\\may\\\\names_chinese.csv\")\n",
    "names_malay = pd.read_csv(\"C:\\\\Users\\\\ijohan\\\\Desktop\\\\TNB_PROJECT\\\\source_data\\\\may\\\\name_malay.csv\")\n",
    "names_indian = pd.read_csv(\"C:\\\\Users\\\\ijohan\\\\Desktop\\\\TNB_PROJECT\\\\source_data\\\\may\\\\name_indian.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity = ethni[['CA Number','Service Request ID','BP Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BP ID</th>\n",
       "      <th>BP Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200774679</td>\n",
       "      <td>MICHELLE LEE CHIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102853741</td>\n",
       "      <td>ANDY HO POON SIEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1102592448</td>\n",
       "      <td>SOPHIAN BIN SIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1200394373</td>\n",
       "      <td>Ahmed Fairuz Bin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100177363</td>\n",
       "      <td>PANG GEOK CHUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        BP ID            BP Name\n",
       "0  1200774679  MICHELLE LEE CHIN\n",
       "1  1102853741  ANDY HO POON SIEW\n",
       "2  1102592448   SOPHIAN BIN SIAN\n",
       "3  1200394373   Ahmed Fairuz Bin\n",
       "4  1100177363     PANG GEOK CHUN"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethni.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_ch = names_ch.loc[names_ch['Race'] == 'chinese']\n",
    "#names_malay = names_malay.loc[names_malay['Race'] == 'Malay']\n",
    "#names_indian = names_indian.loc[names_indian['Race'] == 'Malay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#values_ch = [names_ch['Name'].str]\n",
    "values_ch = names_ch['Name'].tolist()\n",
    "values_indian = names_indian['name'].tolist()\n",
    "values_malay = names_malay['name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ijohan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "ethnicity['BP_Name'] = ethnicity['BP Name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA Number</th>\n",
       "      <th>Service Request ID</th>\n",
       "      <th>BP Name</th>\n",
       "      <th>BP_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210036776002</td>\n",
       "      <td>1000670392</td>\n",
       "      <td>MICHELLE LEE CHIN</td>\n",
       "      <td>michelle lee chin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220307050002</td>\n",
       "      <td>1000674062</td>\n",
       "      <td>ANDY HO POON SIEW</td>\n",
       "      <td>andy ho poon siew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210018089505</td>\n",
       "      <td>1000616785</td>\n",
       "      <td>Ahmed Fairuz Bin</td>\n",
       "      <td>ahmed fairuz bin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220191176003</td>\n",
       "      <td>1000620832</td>\n",
       "      <td>PANG GEOK CHUN</td>\n",
       "      <td>pang geok chun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220049915905</td>\n",
       "      <td>1000627021</td>\n",
       "      <td>FONG KAR WONG</td>\n",
       "      <td>fong kar wong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CA Number  Service Request ID            BP Name            BP_Name\n",
       "0  210036776002          1000670392  MICHELLE LEE CHIN  michelle lee chin\n",
       "1  220307050002          1000674062  ANDY HO POON SIEW  andy ho poon siew\n",
       "2  210018089505          1000616785   Ahmed Fairuz Bin   ahmed fairuz bin\n",
       "3  220191176003          1000620832     PANG GEOK CHUN     pang geok chun\n",
       "4  220049915905          1000627021      FONG KAR WONG      fong kar wong"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CReating pattern for each names and surnames based on ethinicity\n",
    "\n",
    "pattern_ch = '|'.join([r'\\b{}\\b'.format(needle) for needle in values_ch])\n",
    "pattern_indian = '|'.join([r'\\b{}\\b'.format(needle) for needle in values_indian])\n",
    "pattern_malay = '|'.join([r'\\b{}\\b'.format(needle) for needle in values_malay])\n",
    "\n",
    "#df = pd.DataFrame(data=data, columns=['id', 'value'])\n",
    "#result = df[df['value'].str.contains(pattern, regex=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching above patterns with each the BP_Name column in the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chinese\n",
    "result_ch = ethnicity[ethnicity['BP_Name'].str.contains(pattern_ch, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INdian\n",
    "result_indian = ethnicity[ethnicity['BP_Name'].str.contains(pattern_indian, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Malay\n",
    "result_malay = ethnicity[ethnicity['BP_Name'].str.contains(pattern_malay, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ijohan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\ijohan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\ijohan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "result_ch['Race'] = 'Chinese'\n",
    "result_indian['Race'] = 'Indian'\n",
    "result_malay['Race'] = 'Malay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA Number</th>\n",
       "      <th>Service Request ID</th>\n",
       "      <th>BP Name</th>\n",
       "      <th>BP_Name</th>\n",
       "      <th>Race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>220341154603</td>\n",
       "      <td>1000627274</td>\n",
       "      <td>HARMINDER KAUR A/P</td>\n",
       "      <td>harminder kaur a/p</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>220002823807</td>\n",
       "      <td>1000637877</td>\n",
       "      <td>SATKUNAVATHI A/P</td>\n",
       "      <td>satkunavathi a/p</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>220210690102</td>\n",
       "      <td>1000638757</td>\n",
       "      <td>EVALI A/L SUPPIAH</td>\n",
       "      <td>evali a/l suppiah</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>210041591401</td>\n",
       "      <td>1000639040</td>\n",
       "      <td>NARENDRA KUMAR A/L</td>\n",
       "      <td>narendra kumar a/l</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>220011569700</td>\n",
       "      <td>1000639421</td>\n",
       "      <td>BHARTI DEVI A/P</td>\n",
       "      <td>bharti devi a/p</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CA Number  Service Request ID             BP Name             BP_Name  \\\n",
       "7   220341154603          1000627274  HARMINDER KAUR A/P  harminder kaur a/p   \n",
       "21  220002823807          1000637877    SATKUNAVATHI A/P    satkunavathi a/p   \n",
       "32  220210690102          1000638757   EVALI A/L SUPPIAH   evali a/l suppiah   \n",
       "33  210041591401          1000639040  NARENDRA KUMAR A/L  narendra kumar a/l   \n",
       "36  220011569700          1000639421     BHARTI DEVI A/P     bharti devi a/p   \n",
       "\n",
       "      Race  \n",
       "7   Indian  \n",
       "21  Indian  \n",
       "32  Indian  \n",
       "33  Indian  \n",
       "36  Indian  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging all data frames\n",
    "result = pd.concat([result_ch, result_indian,result_malay]).drop_duplicates(subset=['CA Number','Service Request ID','BP Name','Race'], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15763"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ijohan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# filtering the names where ethinicity tag is not observed based on the name and surnames matching.\n",
    "ethnicity['Race'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #substract from the original data and classified based on ethnincity\n",
    "\n",
    "df = pd.concat([ethnicity,result]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ethnicity[~ethnicity['Service Request ID'].isin(result['Service Request ID'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3484"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA Number</th>\n",
       "      <th>Service Request ID</th>\n",
       "      <th>BP Name</th>\n",
       "      <th>BP_Name</th>\n",
       "      <th>Race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>220032066605</td>\n",
       "      <td>1000627421</td>\n",
       "      <td>MENTA CONSTRUCTION</td>\n",
       "      <td>menta construction</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>220288053304</td>\n",
       "      <td>1000629255</td>\n",
       "      <td>PRIMEWORK (M) SDN</td>\n",
       "      <td>primework (m) sdn</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>210113162600</td>\n",
       "      <td>1000632215</td>\n",
       "      <td>THE SUBURBAN FOOD</td>\n",
       "      <td>the suburban food</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>210093934600</td>\n",
       "      <td>1000633750</td>\n",
       "      <td>SOVN (M) SDN BHD</td>\n",
       "      <td>sovn (m) sdn bhd</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>220078641208</td>\n",
       "      <td>1000636667</td>\n",
       "      <td>RAHIM MASOUDI</td>\n",
       "      <td>rahim masoudi</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CA Number  Service Request ID             BP Name             BP_Name  \\\n",
       "8   220032066605          1000627421  MENTA CONSTRUCTION  menta construction   \n",
       "9   220288053304          1000629255   PRIMEWORK (M) SDN   primework (m) sdn   \n",
       "13  210113162600          1000632215   THE SUBURBAN FOOD   the suburban food   \n",
       "14  210093934600          1000633750    SOVN (M) SDN BHD    sovn (m) sdn bhd   \n",
       "18  220078641208          1000636667       RAHIM MASOUDI       rahim masoudi   \n",
       "\n",
       "   Race  \n",
       "8        \n",
       "9        \n",
       "13       \n",
       "14       \n",
       "18       "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"race_missing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"BP_name_with_race.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
